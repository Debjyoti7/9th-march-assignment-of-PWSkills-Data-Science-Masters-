{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce9c0aa-47ec-4068-894b-16bbda9b4cad",
   "metadata": {},
   "source": [
    "# Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f68288-cb21-43bb-9707-e15f945dd5e4",
   "metadata": {},
   "source": [
    "## Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions that describe the probability distribution of a random variable.\n",
    "\n",
    "## The PMF is used for discrete random variables, while the PDF is used for continuous random variables.\n",
    "\n",
    "## The PMF gives the probability that a discrete random variable takes on a specific value, while the PDF gives the probability that a continuous random variable takes on a value within a certain interval.\n",
    "\n",
    "## For example, let's consider a fair six-sided die. The PMF of the die would give the probability that the die takes on a specific value, which is 1/6 for each possible outcome (1, 2, 3, 4, 5, or 6). So, for instance, the PMF of the die would be:\n",
    "\n",
    "## P(X = 1) = 1/6\n",
    "## P(X = 2) = 1/6\n",
    "## P(X = 3) = 1/6\n",
    "## P(X = 4) = 1/6\n",
    "## P(X = 5) = 1/6\n",
    "## P(X = 6) = 1/6\n",
    "\n",
    "## On the other hand, let's consider a continuous random variable, such as the height of adult men in a certain population. The PDF of this variable would give the probability that a man's height falls within a certain range. For example, the PDF might show that the probability of a man's height being between 5'10\" and 6' is 0.12. However, the probability of a man's height being exactly 6' is zero, since the variable is continuous and there are an infinite number of possible values within any given interval.\n",
    "\n",
    "## Overall, PMF and PDF are important concepts in probability theory and statistics, as they help describe the probability distribution of random variables, and enable us to make predictions and draw inferences from data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d41f84d-390e-4831-933a-00582cf0f6b5",
   "metadata": {},
   "source": [
    "# Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d4c76-f14e-42e4-bdfc-a24b800c1b2c",
   "metadata": {},
   "source": [
    "## The Cumulative Density Function (CDF) is a function that describes the probability that a random variable X takes on a value less than or equal to a given value x. It is defined as:\n",
    "\n",
    "## F(x) = P(X ≤ x)\n",
    "\n",
    "## The CDF is used to describe the cumulative distribution of a random variable, which shows the probability that the variable is less than or equal to a given value.\n",
    "\n",
    "## For example, let's consider the toss of a fair coin. The CDF of the number of heads in two tosses can be represented as follows:\n",
    "\n",
    "## X = number of heads in two tosses\n",
    "\n",
    "## F(x) = P(X ≤ x)\n",
    "\n",
    "## F(0) = P(X ≤ 0) = 0.25 (since the possible outcomes are HH, HT, TH, and TT, and only TT has zero heads)\n",
    "## F(1) = P(X ≤ 1) = 0.75 (since the possible outcomes are HH, HT, TH, and TT, and three of these have one or fewer heads)\n",
    "## F(2) = P(X ≤ 2) = 1.00 (since the possible outcomes are HH, HT, TH, and TT, and all of these have two or fewer heads)\n",
    "\n",
    "## In this case, the CDF shows the cumulative probabilities of obtaining 0, 1, or 2 heads in two tosses of a fair coin.\n",
    "\n",
    "## The CDF is used because it provides a way to calculate the probability that a random variable takes on a value less than or equal to a given value. This can be useful in many applications, such as in finance, where the CDF of a stock price can be used to calculate the probability that the stock will be worth a certain amount at a certain time in the future. Additionally, the CDF can be used to derive other important functions, such as the probability density function (PDF) and the survival function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980c3ac-14f2-49ad-934c-d3d4efc7cb52",
   "metadata": {},
   "source": [
    "# Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85128f0-082a-4953-a994-52f6daca3db2",
   "metadata": {},
   "source": [
    "## The normal distribution is commonly used to model continuous random variables in a wide range of fields, including natural and social sciences, engineering, finance, and statistics. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "## Heights of people in a population\n",
    "## Weights of objects produced in a manufacturing process\n",
    "## Test scores on a standardized exam\n",
    "## Errors in measurement or observation\n",
    "## Financial returns on an investment portfolio\n",
    "## The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, while the standard deviation determines the spread of the distribution around the mean.\n",
    "\n",
    "## When μ=0 and σ=1, the distribution is known as the standard normal distribution. The shape of the normal distribution is bell-shaped, symmetric, and unimodal, meaning that it has a single peak at the mean. The area under the curve of the normal distribution is equal to 1, and the curve extends to infinity in both positive and negative directions. The majority of the data falls within a few standard deviations of the mean, with the probability of observing a value that is more than 3 standard deviations from the mean being very low.\n",
    "\n",
    "## The mean and standard deviation can be used to calculate probabilities for specific values or ranges of values of the random variable that is being modeled by the normal distribution. For example, if X is normally distributed with mean μ and standard deviation σ, then the probability of observing a value less than or equal to x is given by the cumulative distribution function (CDF) of X:\n",
    "\n",
    "## P(X ≤ x) = Φ((x-μ)/σ)\n",
    "\n",
    "## where Φ is the CDF of the standard normal distribution. This formula can be used to find the probability of observing a value within a certain range or to calculate confidence intervals for estimates of population parameters based on sample data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01122a9-e180-4740-8377-1b1b9e716d43",
   "metadata": {},
   "source": [
    "# Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a7e4a-0186-43ad-8279-1ef8bd1bb75b",
   "metadata": {},
   "source": [
    "## The normal distribution is an essential concept in statistics and probability theory. Its importance lies in the fact that it is a fundamental model that describes the behavior of many natural and social phenomena in the real world. Some of the key reasons why the normal distribution is important are:\n",
    "\n",
    "## 1. Central Limit Theorem: The normal distribution is closely related to the Central Limit Theorem, which states that the sum of a large number of independent and identically distributed random variables will tend towards a normal distribution, regardless of the original distribution of the variables. This theorem has numerous applications in areas such as quality control, finance, and epidemiology.\n",
    "\n",
    "## 2. Inference: The normal distribution is often used as a model for continuous random variables in statistical inference. It is used to estimate population parameters, such as means and variances, based on sample data. The properties of the normal distribution allow us to construct confidence intervals and conduct hypothesis testing for such estimates.\n",
    "\n",
    "## 3. Predictive modeling: The normal distribution is often used as a model for the distribution of errors in predictive models. This allows us to make predictions about future outcomes based on historical data.\n",
    "\n",
    "## 4. Universal applicability: The normal distribution is applicable to a wide range of real-world phenomena, from physical measurements such as height and weight to social phenomena such as income and test scores.\n",
    "\n",
    "## Some real-life examples of phenomena that follow a normal distribution include:\n",
    "\n",
    "## Heights of adult humans, Weights of produce in a field or factory, IQ scores on standardized tests, Blood pressure measurements in a population, Annual rainfall amounts in a region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e335b39-50d0-49fc-b4f9-81f144044cbf",
   "metadata": {},
   "source": [
    "# Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3eaa5a-fc23-4059-9645-367d9eca12ea",
   "metadata": {},
   "source": [
    "## The Bernoulli distribution is a discrete probability distribution that models the outcomes of a single binary experiment, where the outcome can be either success or failure. It is named after the Swiss mathematician, Jakob Bernoulli. The Bernoulli distribution has a single parameter, p, which represents the probability of success in the experiment.\n",
    "\n",
    "## For example, consider a coin toss experiment where we are interested in the outcome of getting heads. If we define success as getting heads and failure as getting tails, then the Bernoulli distribution can be used to model the probability of getting heads in a single coin toss.\n",
    "\n",
    "## The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "## P(X = x) = p^x (1-p)^(1-x) for x = 0, 1\n",
    "\n",
    "## where X is the random variable representing the outcome of the experiment.\n",
    "\n",
    "## The key difference between the Bernoulli distribution and the Binomial distribution is that the Bernoulli distribution models the outcome of a single binary experiment, while the Binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. In other words, the Binomial distribution is the sum of multiple Bernoulli trials.\n",
    "\n",
    "## For example, consider flipping a coin 10 times and counting the number of heads. The outcome of each coin toss can be modeled using a Bernoulli distribution, while the total number of heads can be modeled using a Binomial distribution.\n",
    "\n",
    "## The probability mass function (PMF) of the Binomial distribution is given by:\n",
    "\n",
    "## P(X = k) = (n choose k) p^k (1-p)^(n-k) for k = 0, 1, 2, ..., n\n",
    "\n",
    "## where X is the random variable representing the number of successes, n is the total number of trials, p is the probability of success in each trial, and (n choose k) is the binomial coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f31f31-924b-4c5f-990d-d30a9a252c0f",
   "metadata": {},
   "source": [
    "# Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater  than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1874e35f-61f7-4a47-84fe-8c9fc6c58e06",
   "metadata": {},
   "source": [
    "## To calculate the probability that a randomly selected observation from a normally distributed dataset with mean 50 and standard deviation 10 will be greater than 60, we can use the standard normal distribution.\n",
    "\n",
    "## First, we need to standardize the value 60 using the formula:\n",
    "\n",
    "## z = (x - μ) / σ\n",
    "\n",
    "## where x is the value we want to standardize, μ is the mean of the dataset, and σ is the standard deviation of the dataset.\n",
    "\n",
    "## Substituting the values we have:\n",
    "\n",
    "## z = (60 - 50) / 10 = 1\n",
    "\n",
    "## We then use a standard normal distribution table or a calculator to find the probability that a standard normal variable is greater than 1. The probability is approximately 0.1587.\n",
    "\n",
    "## Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d06f70-e06a-4012-a919-4da9dbeb3e07",
   "metadata": {},
   "source": [
    "# Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97687e27-9e67-4026-b47f-035d4eb7c0ff",
   "metadata": {},
   "source": [
    "## Uniform distribution is a continuous probability distribution where all possible outcomes within a given range are equally likely to occur. In other words, the probability of any particular value occurring is the same as the probability of any other value occurring within the given range.\n",
    "\n",
    "## An example of uniform distribution can be the outcome of rolling a fair six-sided dice. Each face of the dice has an equal probability of 1/6 of showing up, and the probability of rolling any number between 1 and 6 is the same. The uniform distribution for this example can be represented by the following probability density function:\n",
    "\n",
    "## f(x) = 1/6, for x = 1, 2, 3, 4, 5, 6\n",
    "\n",
    "## where f(x) is the probability density function and x is the possible outcome of rolling the dice.\n",
    "\n",
    "## Another example of uniform distribution can be the distribution of heights of students in a class, assuming that heights are uniformly distributed between a minimum and maximum height. In this case, the probability of a student being a certain height between the minimum and maximum values is the same for any two students, as long as they fall within that range.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb13ae0-bb8f-466d-9b7b-04af2af69e1d",
   "metadata": {},
   "source": [
    "# Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218ee4c-8bbf-4a37-8db3-3b655ff56b9d",
   "metadata": {},
   "source": [
    "## A z-score (also known as a standard score) is a way to measure how many standard deviations an observation or data point is away from the mean of a dataset. It is calculated by subtracting the mean of the dataset from the observation and then dividing by the standard deviation of the dataset.\n",
    "\n",
    "## The formula for calculating z-score is as follows:\n",
    "\n",
    "## z = (x - μ) / σ\n",
    "\n",
    "## where x is the observation, μ is the mean of the dataset, and σ is the standard deviation of the dataset.\n",
    "\n",
    "## The z-score helps us to standardize the data and compare values from different datasets that have different scales and variances. It allows us to identify how extreme or unusual a particular observation is compared to the rest of the dataset. A positive z-score means the observation is above the mean of the dataset, while a negative z-score means the observation is below the mean of the dataset.\n",
    "\n",
    "## The importance of z-score lies in its ability to help us make meaningful comparisons between observations and datasets. By converting raw data into standardized scores, we can analyze and interpret data more easily and effectively, and make inferences about the population from a sample. Additionally, z-score is widely used in statistical hypothesis testing, where it can be used to determine if an observation is statistically significant or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60a747-ce98-4f9f-8d9d-5ed40eb28890",
   "metadata": {},
   "source": [
    "# Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0a1d3-5403-434e-9153-293ff0fd2618",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that as the sample size increases, the sampling distribution of the sample mean will become more normally distributed, regardless of the distribution of the population from which the sample is drawn. In other words, the mean of the sample means will approach the population mean, and the standard deviation of the sample means will decrease as the sample size increases.\n",
    "\n",
    "## The significance of the Central Limit Theorem lies in its ability to allow us to make inferences about the population from a sample. This is because the CLT implies that the sample means will be distributed normally around the population mean, regardless of the underlying distribution of the population. This allows us to estimate the population parameters with greater accuracy and precision, and to make predictions about the population based on the sample data.\n",
    "\n",
    "## The CLT is widely used in statistical inference, hypothesis testing, and confidence interval estimation. It is also used in quality control, finance, engineering, and many other fields where statistical analysis is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25d517-66bb-42f7-b221-10d7048f86af",
   "metadata": {},
   "source": [
    "# Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b65f3-c02d-4943-a367-4a6a7be24323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that as the sample size increases, the sampling distribution of the sample mean will become more normally distributed, regardless of the distribution of the population from which the sample is drawn. However, there are some key assumptions that need to be met for the CLT to hold true:\n",
    "\n",
    "## The sample is drawn from a population with a finite variance: The population from which the sample is drawn should have a finite variance. If the population has an infinite variance or the variance is unknown, the CLT may not hold.\n",
    "\n",
    "## The sample size is large enough: The sample size should be large enough for the CLT to hold. Typically, a sample size of at least 30 is considered large enough for the CLT to be applicable.\n",
    "\n",
    "## The samples are independent: The observations within the sample should be independent of each other. In other words, the observation in one sample should not influence the observation in another sample.\n",
    "\n",
    "## The sampling is random: The sample should be drawn from the population using a random sampling method to ensure that the sample is representative of the population.\n",
    "\n",
    "## The population distribution does not need to be normal: The CLT holds true regardless of the distribution of the population, as long as the above assumptions are met.\n",
    "\n",
    "## It is important to note that these assumptions are not always met in real-world situations. In such cases, alternative statistical methods may need to be used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
